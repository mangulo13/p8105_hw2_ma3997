---
title: "Homework 2"
author: Matthew Angulo
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset. 

```{r}
trashwheel_df = 
        read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                  sheet = "Mr. Trash Wheel",
                  range = cell_cols("A:N")) %>% 
        janitor::clean_names() %>% 
        drop_na(dumpster) %>% 
        mutate(
                sports_balls = round(sports_balls),
                sports_balls = as.integer(sports_balls)) %>% 
        view
median(pull(trashwheel_df, sports_balls))
```

Read precipitation data

```{r}
precip_2018 = 
        read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                   sheet = "2018 Precipitation",
                   skip = 1) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2018) %>% 
        relocate(year) %>% 
        view


precip_2017 = 
        read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                   sheet = "2017 Precipitation",
                   skip = 1) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2017) %>% 
        relocate(year)

```

Now combine annual precipitation. 

```{r}
month_df = 
        tibble(
                month = 1:12,
                month_name = month.name
        )

precip_df = 
        bind_rows(precip_2018, precip_2017) 

left_join(precip_df, month_df, by = "month") %>% 
        view

```


This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, MD. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. 

The total precipitation for 2018 was `r sum(pull(precip_2018, "total"))` inches. 

The median number of sports balls in 2018 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`.


## Problem 2

Read the NYC Transit data

```{r}
transit_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
        janitor::clean_names() %>%
        select(line:entry, vending, ada) %>%
        mutate(entry = recode(entry,YES = TRUE, NO = FALSE))%>% 
        view
      
```

This dataset contains information on the subway lines in New York City including station names, location, entrances, routes, and ADA compliance. There are `r nrow(transit_df)` rows and `r ncol(transit_df)` columns in this dataset. The data was tidied by cleaning column names, selecting columns of interest, and reformatting "entry" as a logical variable instead of character.

This dataset is not super tidy. Routes are untidy with observations and variables as longer than wider. 

Let's look at the number of unique stations, those that are ADA compliant, and those without vending that allow entry. 

```{r}
distinct(transit_df, line, station_name) %>% 
        count()

filter(transit_df, ada == TRUE) %>% 
        distinct(line, station_name) %>% 
        count()

with_entry = filter(transit_df, vending == "NO", entry == TRUE) %>% 
        distinct(line, station_name) %>% 
        count()
        
total = filter(transit_df, vending == "NO") %>% 
        distinct(line, station_name) %>% 
        count()

```

There are `r count(distinct(transit_df, line, station_name))` unique subway stations in NYC. 

Of those stations, only `r filter(transit_df, ada == TRUE) %>% distinct(line, station_name) %>% count()` are ADA compliant. 

`r with_entry` out of `r total` stations without vending allow entrance. 

Let's tidy up the data by creating a route_name and route_number variable. Afterwards we'll look at how many stations are on the A line and how many of those are ADA compliant. 
```{r}
transit_tidy = 
        transit_df %>%
        mutate_at(vars(route1:route11), as.character) %>% 
        pivot_longer(route1:route11,
                     names_to = "route_number",
                     names_prefix = "route",
                     values_to = "route_name" ) %>% 
        drop_na(route_name) %>% 
        view


a_train = filter(transit_tidy, route_name == "A") %>% 
        distinct(line, station_name) %>% 
        view

a_count = count(a_train)

a_ada = filter(transit_tidy, route_name == "A", ada == TRUE) %>% 
        distinct(line, station_name) %>% 
        count()

```

There are `r a_count` stations that service the A line. Of those `r a_ada` are ADA compliant. 

## Problem 3

Let's first read in and clean the data from pols-month.csv

```{r}
pols_df = read_csv("./data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate_at(vars(year:day), as.integer) 

month_df = 
  tibble(
    month = 1:12,
    month_name = month.abb
  )

pols_tidy = 
  left_join(pols_df, month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>%
  mutate(president = case_when(
    prez_gop == 1 ~ 'gop',
    prez_gop == 2 ~ 'gop',
    prez_dem == 1 ~ 'dem'
  )) %>%
  select(-prez_gop, -prez_dem, -day) %>% 
  relocate(year, month) %>% 
  view
```

Now let's read in and clean the data from snp.csv
```{r}
snp_df = read_csv("./data/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year")) %>% 
  mutate_at(vars(month:year), as.integer) %>% 
  view 

snp_tidy = 
  left_join(snp_df, month_df, by = "month") %>%
  select(-month) %>% 
  rename(month = month_name) %>%
  relocate(year, month) %>% 
  view
```

Now let's read in and clean the data from unemployment.csv
```{r}
unemploy_tidy = read_csv("./data/unemployment.csv") %>% 
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = 'month',
    values_to = 'unemployment'
  ) %>% 
 mutate( month = str_to_title(month)) %>% 
  view

```

Now, we can merge datasets. Let's start with merging snp into pols and then the combined dataset into a final with the unmployment spreadsheet.

```{r}
combine_df = left_join(pols_tidy, snp_tidy, by = c("year", "month")) %>% 
  view

final_df = left_join(combine_df, unemploy_tidy, by = c("year", "month")) %>% 
  relocate(year, month, day) %>% 
  view
```


There are three datasets that we have combined into one final set. 

The first, pols-month, is a count of republican and democrat politicians by a given year and month denoted with the variables gov_, sen_, rep_, and prez_ followed by their party. Upon cleaning, the pols_tidy dataset contains `r nrow(pols_tidy)` months from the year `r min(pull(pols_tidy, year))` to `r max(pull(pols_tidy, year))`. 

The second, snp, is the Standard & Poor's stock market index at the start of each month from `r min(pull(snp_tidy, year))` to `r max(pull(snp_tidy, year))`: total `r nrow(snp_tidy)` months. 

The third, unemployment, reports the percentage of unemployment for each month from `r min(pull(unemploy_tidy, year))` to `r max(pull(unemploy_tidy, year))` accounting for `r nrow(unemploy_tidy)` months. 

The combined dataset, final_df, reports the number of politicians by party, which party held the presidency, the S&P index, and percent unemployed  from `r min(pull(final_df, year))` to `r max(pull(final_df, year))` for a total reporting period of `r nrow(final_df)` months
